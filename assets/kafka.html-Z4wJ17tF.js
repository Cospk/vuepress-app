import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as i,d as t,o as s}from"./app-CG6bgqhH.js";const p={};function o(n,e){return s(),i("div",null,e[0]||(e[0]=[t('<p>这个版本就渐进式了解kafka</p><p>假设两个服务：A和B</p><p>B服务处理消息能力是100qps、但是A服务可发送200pqs，这么多的消息请求过来B服务很容易跨掉，那如何可用做的A可用正常产生这么多消息，B不被压垮并处理掉A的消息呢？</p><p>加一层<strong>中间层 -- 消息队列kafka</strong></p><figure><img src="https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/kafka_simper1.jpeg" alt="kafka_simper1" tabindex="0" loading="lazy"><figcaption>kafka_simper1</figcaption></figure><p>先总结一些：</p><ul><li>kafka 是消息队列，像消息队列投递消息的是生产者，消费消息的是消费者。增加生产者和消费者的实例个数可以提升系统吞吐。多个消费者可以组成一个消费者组，不同消费者组维护自己的消费进度，互不打搅。</li><li>kafka 将消息分为多个 topic，每个 topic 内部拆分为多个 partition，每个 partition 又有自己的副本，不同的 partition 会分布在不同的 broker 上，提升性能的同时，还增加了系统可用性和可扩展性。</li></ul><h2 id="什么是消息队列" tabindex="-1"><a class="header-anchor" href="#什么是消息队列"><span>什么是消息队列</span></a></h2><p>我们首先可用想到的是在B服务中单独加一个队列，存储和消费消息,然后队列可用通过链表的结构，用一个offset定位处理的位置，这样B根据能力进行处理，执行完一个移动offset位置即可</p><img src="https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/mq_simper1.jpeg" alt="mq_simper1" style="zoom:40%;"><figure><img src="https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/mq_simperOffset.jpeg" alt="mq_simperOffset" tabindex="0" loading="lazy"><figcaption>mq_simperOffset</figcaption></figure><p>上面这个还有一个问题：若是B服务会奔溃。消息直接全部丢失，那怎么解决呢？</p><p>用一个服务单独处理这些消息队列，即使B服务挂了也不影响。</p><img src="https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/mq_simperOneServer.jpeg" alt="mq_simperOneServer" style="zoom:50%;"><figure><img src="https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/mq_simperProducerConsumer.jpeg" alt="mq_simperProducerConsumer" tabindex="0" loading="lazy"><figcaption>mq_simperProducerConsumer</figcaption></figure><p>但这个只是一个简陋的消息组件，并没有高可用可性能高扩展的特性，下面开始优化</p><h2 id="高性能" tabindex="-1"><a class="header-anchor" href="#高性能"><span>高性能</span></a></h2><p>若是单个A和B的话，这个消息队列的吞吐量是很受限的，性能会很差，且消息队列会一直堆积直到奔溃，这么解决？</p><p>解决方案：增加A和B的数量、将队列按topic拆分、一个topic继续拆分为Partiton让一个B对应一个Partition</p><p>@slidestart</p><ul><li><p>提升性能，我们可用扩展多个消费者和生产者，这样消息队列的吞吐量就上去了</p><figure><img src="https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/mq_simper2.jpeg" alt="mq_simper2" tabindex="0" loading="lazy"><figcaption>mq_simper2</figcaption></figure></li></ul><hr><ul><li>消息队列有点多，就将消息队列按照topic进行分类，比如topic1、topic2等等，减低topic压力</li></ul><figure><img src="https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/mq_simper3.jpeg" alt="mq_simper3" tabindex="0" loading="lazy"><figcaption>mq_simper3</figcaption></figure><hr><ul><li><p>单个topic还是有点多，单个topic拆分几段，每段就是一个partition分区，每个消费者负责一个partition</p><figure><img src="https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/kafka_simperPartition.jpeg" alt="kafka_simperPartition" tabindex="0" loading="lazy"><figcaption>kafka_simperPartition</figcaption></figure></li></ul><p>@slideend</p><h2 id="高扩展" tabindex="-1"><a class="header-anchor" href="#高扩展"><span>高扩展</span></a></h2><p>随着 partition 变多，如果 partition 都在同一台机器上的话，就会导致单机 cpu 和内存过高影响整体系统性能。</p><p>继续优化：申请更多设备，然后将partition分散部署到多个设备。这样拆分一个机器就是一个broker来缓解</p><figure><img src="https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/kafka_simperBroker.png" alt="image-20250103181643832" tabindex="0" loading="lazy"><figcaption>image-20250103181643832</figcaption></figure><h2 id="高可用" tabindex="-1"><a class="header-anchor" href="#高可用"><span>高可用</span></a></h2><p>上面这个还存在问题：若是一个partition所在的broker挂了，那里面的消息不直接丢失了嘛，就扯不上高可用了。</p><p>解决方案：怕丢失都会想到多做备份嘛，然后可用考虑分布式存储系统使用的raft算法，来保证单个节点故障时保证一致性和高可用性</p><p>我们可用为partition做一些副本，也就是replicas，并将这些分为Leader和Follower</p><ul><li>leader：负责生产者和消费者的读写请求</li><li>Follower：只管同步leader的消息</li></ul><p>@slidestart</p><ul><li><p>正常运行时，follower会一直同步leader的消息（做备份）</p><figure><img src="https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/kafka_simperReplicas.jpeg" alt="kafka_simperReplicas" tabindex="0" loading="lazy"><figcaption>kafka_simperReplicas</figcaption></figure></li></ul><hr><ul><li>Leader所在的broker挂了，会从Follower选举一个作为leader继续工作</li></ul><figure><img src="https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/kafka_simperAva.jpeg" alt="kafka_simperAva" tabindex="0" loading="lazy"><figcaption>kafka_simperAva</figcaption></figure><p>@slideend</p><h2 id="持久化和过期策略" tabindex="-1"><a class="header-anchor" href="#持久化和过期策略"><span>持久化和过期策略</span></a></h2><p>若是挂一个broker还可用继续可用，那极端点，所有都挂了呢？数据直接丢失了</p><p>为此还是要额外将数据存储到磁盘中去做持久化，这样重启依旧可继续工作</p><p>那还会有问题：数据一直存储的话磁盘会奔溃，为此还有给一个保存的策略 -- retention policy（比如超过大小或者超过一定的时限就会清除掉）</p><h2 id="zookeeper" tabindex="-1"><a class="header-anchor" href="#zookeeper"><span>zookeeper</span></a></h2><p>好像上面组件太多了，而且每个组件都有自己的数据和状态，所以还需要有个组件去统一维护这些组件的状态信息，于是我们引入 <strong>ZooKeeper</strong> 组件。通过定期于broker通信获取整个集群的状态，判断哪些broker可用</p><figure><img src="https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/kafka_simperZookeeper.jpeg" alt="kafka_simperZookeeper" tabindex="0" loading="lazy"><figcaption>kafka_simperZookeeper</figcaption></figure><h2 id="kafka是什么" tabindex="-1"><a class="header-anchor" href="#kafka是什么"><span>Kafka是什么？</span></a></h2><p>到这里，当初那个简陋的消息队列，就成了一个高性能，高扩展性，高可用，支持持久化的超强消息队列，没错，它就是我们常说的消息队列 <strong>Kafka</strong>，上面涉及到各种概念，比如 partition 和 broker 什么的，都出自它。</p><figure><img src="https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/kafka_simperKafka.jpeg" alt="kafka_simperKafka" tabindex="0" loading="lazy"><figcaption>kafka_simperKafka</figcaption></figure><h2 id="kafka的使用场景" tabindex="-1"><a class="header-anchor" href="#kafka的使用场景"><span>kafka的使用场景</span></a></h2><p>消息队列是架构中最常见的中间件之一，使用场景之多，堪称万金油！<br> 比如上游流量忽高忽低，想要<strong>削峰填谷</strong>，提升 cpu/gpu 利用率，用它。<br> 又比如系统过大，消息流向盘根错节，想要拆解组件，<strong>降低系统耦合</strong>，还是用它。<br> 再比如秒杀活动，请求激增，想要<strong>保护服务</strong>的同时又尽量不影响用户，还得用它。<br> 当然，凡事无绝对，方案还得根据实际情况来定，做架构做到最后，都是在做<strong>折中</strong></p>',54)]))}const c=a(p,[["render",o],["__file","kafka.html.vue"]]),g=JSON.parse('{"path":"/middleware/%E6%B6%88%E6%81%AF%E7%BB%84%E4%BB%B6/kafka.html","title":"Kafka-xiaobai","lang":"zh-CN","frontmatter":{"title":"Kafka-xiaobai","order":1,"author":"xiaoxie","date":"2025-01-01T00:00:00.000Z","tag":["mq"],"star":true,"description":"这个版本就渐进式了解kafka 假设两个服务：A和B B服务处理消息能力是100qps、但是A服务可发送200pqs，这么多的消息请求过来B服务很容易跨掉，那如何可用做的A可用正常产生这么多消息，B不被压垮并处理掉A的消息呢？ 加一层中间层 -- 消息队列kafka kafka_simper1kafka_simper1 先总结一些： kafka 是消息...","head":[["meta",{"property":"og:url","content":"https://Cospk.github.io/vuepress-app/middleware/%E6%B6%88%E6%81%AF%E7%BB%84%E4%BB%B6/kafka.html"}],["meta",{"property":"og:site_name","content":"Golang全栈指南"}],["meta",{"property":"og:title","content":"Kafka-xiaobai"}],["meta",{"property":"og:description","content":"这个版本就渐进式了解kafka 假设两个服务：A和B B服务处理消息能力是100qps、但是A服务可发送200pqs，这么多的消息请求过来B服务很容易跨掉，那如何可用做的A可用正常产生这么多消息，B不被压垮并处理掉A的消息呢？ 加一层中间层 -- 消息队列kafka kafka_simper1kafka_simper1 先总结一些： kafka 是消息..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/kafka_simper1.jpeg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-01-17T08:43:17.000Z"}],["meta",{"property":"article:author","content":"xiaoxie"}],["meta",{"property":"article:tag","content":"mq"}],["meta",{"property":"article:published_time","content":"2025-01-01T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-01-17T08:43:17.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Kafka-xiaobai\\",\\"image\\":[\\"https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/kafka_simper1.jpeg\\",\\"https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/mq_simperOffset.jpeg\\",\\"https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/mq_simperProducerConsumer.jpeg\\",\\"https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/mq_simper2.jpeg\\",\\"https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/mq_simper3.jpeg\\",\\"https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/kafka_simperPartition.jpeg\\",\\"https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/kafka_simperBroker.png\\",\\"https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/kafka_simperReplicas.jpeg\\",\\"https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/kafka_simperAva.jpeg\\",\\"https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/kafka_simperZookeeper.jpeg\\",\\"https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/kafka_simperKafka.jpeg\\"],\\"datePublished\\":\\"2025-01-01T00:00:00.000Z\\",\\"dateModified\\":\\"2025-01-17T08:43:17.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"xiaoxie\\"}]}"]]},"headers":[{"level":2,"title":"什么是消息队列","slug":"什么是消息队列","link":"#什么是消息队列","children":[]},{"level":2,"title":"高性能","slug":"高性能","link":"#高性能","children":[]},{"level":2,"title":"高扩展","slug":"高扩展","link":"#高扩展","children":[]},{"level":2,"title":"高可用","slug":"高可用","link":"#高可用","children":[]},{"level":2,"title":"持久化和过期策略","slug":"持久化和过期策略","link":"#持久化和过期策略","children":[]},{"level":2,"title":"zookeeper","slug":"zookeeper","link":"#zookeeper","children":[]},{"level":2,"title":"Kafka是什么？","slug":"kafka是什么","link":"#kafka是什么","children":[]},{"level":2,"title":"kafka的使用场景","slug":"kafka的使用场景","link":"#kafka的使用场景","children":[]}],"git":{"createdTime":1734622519000,"updatedTime":1737103397000,"contributors":[{"name":"xiaoxie001","username":"xiaoxie001","email":"xie18115@outlook.com","commits":4,"url":"https://github.com/xiaoxie001"}]},"readingTime":{"minutes":4.94,"words":1482},"filePathRelative":"middleware/消息组件/kafka.md","localizedDate":"2025年1月1日","autoDesc":true,"excerpt":"<p>这个版本就渐进式了解kafka</p>\\n<p>假设两个服务：A和B</p>\\n<p>B服务处理消息能力是100qps、但是A服务可发送200pqs，这么多的消息请求过来B服务很容易跨掉，那如何可用做的A可用正常产生这么多消息，B不被压垮并处理掉A的消息呢？</p>\\n<p>加一层<strong>中间层 -- 消息队列kafka</strong></p>\\n<figure><img src=\\"https://gavvy-cloud.oss-cn-shenzhen.aliyuncs.com/web/kafka_simper1.jpeg\\" alt=\\"kafka_simper1\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>kafka_simper1</figcaption></figure>"}');export{c as comp,g as data};
